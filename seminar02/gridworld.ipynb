{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridworld"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this seminar we implement an example of the agent-environment interface used in reinforcement learning, called \"gridworld\".\n",
    "\n",
    "The world consists of an $n \\times m$ grid of squares, indexed by $(i,j)$ with $i = 0, 1, \\dots, n-1$ and $j = 0, 1, \\dots, m-1$.\n",
    "\n",
    "The state of the environment consists of the player being in one of the squares.\n",
    "\n",
    "The possible actions are steps in the directions \"UP\", \"RIGHT\", \"DOWN\", \"LEFT\".\n",
    "\n",
    "The rewards and states after each action can depend on multiple factors:\n",
    "- Some squares can give positive/negative rewards\n",
    "- Squares might be \"blocked\" and not possible to step on\n",
    "- Stepping off the board is impossible\n",
    "- Invalid moves might give a negative reward as \"punishment\"\n",
    "- There might be \"portals\" that take the player to a distant square, regardless of their action\n",
    "- There might be deterministic or random effects that change the outcome of actions, e.g. \"wind\" or \"ice\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variants of this gridworld can be used to illustrate a wide range of concepts and algorithms in reinforcement learning.\n",
    "For instance, in [Sutton & Barto](http://incompleteideas.net/book/the-book-2nd.html) see:\n",
    "- Example 3.5, 3.8\n",
    "- Figure 4.1\n",
    "- Example 6.5, 6.6\n",
    "- Figure 7.4\n",
    "- Example 8.1, 8.3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either implement this class in a separate module (recommended) or inside a Jupyter cell, see `reuseCode.ipynb` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a suggested skeleton of a `GridWorld` class, feel free to modify or rename everything.\n",
    "If you want to implement this class in a separate module, create a new file `gridworld.py`, copy the code there, and delete this code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "RIGHT= np.array([1,0])\n",
    "LEFT = np.array([-1,0])\n",
    "UP= np.array([0,1])\n",
    "DOWN = np.array([0,-1])\n",
    "DIRECTION = (RIGHT,LEFT,UP,DOWN)\n",
    "GAMMA = 0.9\n",
    "THETA = 0.001\n",
    "\n",
    "class GridWorld:\n",
    "\n",
    "    def __init__(self, height, width):\n",
    "        # Store the height and width as attributes\n",
    "        self.height = height #how big second cordinate can be\n",
    "        self.width = width #how big first cordinate can be\n",
    "\n",
    "        self.teleportation = dict()\n",
    "        self.rewardPlace = dict()\n",
    "        self.forbiddenPlace = list()\n",
    "        self.blockedPlace = list()\n",
    "        self.setBorder()\n",
    "        self.totalReward = 0\n",
    "        self.icePlace= list()\n",
    "        self.windPlace = list()\n",
    "        # Initialize the player position\n",
    "        self.pos = np.array([0,0])\n",
    "        \n",
    "    def setBorder(self):\n",
    "        for i in range(self.height):\n",
    "            self.forbiddenPlace.append(np.array([-1,i]))\n",
    "            self.forbiddenPlace.append(np.array([self.width,i]))\n",
    "        for i in range(self.width):\n",
    "            self.forbiddenPlace.append(np.array([i,-1]))\n",
    "            self.forbiddenPlace.append(np.array([i,self.height]))\n",
    "\n",
    "    def evalAction(self,action,values,returnIfBlocked=False,theoricalPos=None,meanReward=0):\n",
    "        if theoricalPos is None:\n",
    "            theoricalPos = self.pos.copy()\n",
    "        if any( (theoricalPos == place ).all() for place in self.forbiddenPlace):\n",
    "            return -float('inf')\n",
    "        if not (any( (theoricalPos + action == place ).all() for place in self.forbiddenPlace)):\n",
    "            theoricalPos = theoricalPos +action\n",
    "        else: #when blocked\n",
    "            meanReward += -1\n",
    "            if returnIfBlocked:\n",
    "                return meanReward + GAMMA*values[theoricalPos[0]][theoricalPos[1]]\n",
    "        \n",
    "        #when ice\n",
    "        for place in self.icePlace:\n",
    "            if np.array_equal(theoricalPos,place):\n",
    "                return self.evalAction(action,values,returnIfBlocked=True,theoricalPos=theoricalPos,meanReward=meanReward)\n",
    "        #when wind\n",
    "        for place in self.windPlace:\n",
    "            if np.array_equal(theoricalPos,place):\n",
    "                partial=0\n",
    "                for direction in DIRECTION:\n",
    "                    partial+=0.25*self.evalAction(direction,values,True,theoricalPos=theoricalPos,meanReward=meanReward)\n",
    "                return partial\n",
    "\n",
    "        #when teleport\n",
    "        for place in self.teleportation:\n",
    "            if np.array_equal(theoricalPos, np.array(place)) :\n",
    "                theoricalPos = self.teleportation[place]\n",
    "                meanReward += self.rewardPlace[place]\n",
    "                \n",
    "        return meanReward + GAMMA*values[theoricalPos[0]][theoricalPos[1]]\n",
    "\n",
    "    # A method to perform an action:\n",
    "    def step(self,action,returnIfBlocked=False):\n",
    "        print(self.pos + action)\n",
    "        if not (any( (self.pos + action == place ).all() for place in self.forbiddenPlace)):\n",
    "            self.pos += action\n",
    "        else: #when blocked\n",
    "            self.totalReward += -1\n",
    "            print(self.totalReward)\n",
    "            if returnIfBlocked:\n",
    "                return\n",
    "        \n",
    "        #when ice\n",
    "        for place in self.icePlace:\n",
    "            if np.array_equal(self.pos,place):\n",
    "                print(\"icy\")\n",
    "                self.step(action,True)\n",
    "        #when wind\n",
    "        for place in self.windPlace:\n",
    "            if np.array_equal(self.pos,place):\n",
    "                print(\"windy\")\n",
    "                self.step(random.choice(DIRECTION),True)\n",
    "\n",
    "        #when teleport\n",
    "        for place in self.teleportation:\n",
    "            if np.array_equal(self.pos, np.array(place)) :\n",
    "                print(\"teleport\")\n",
    "                self.pos = self.teleportation[place]\n",
    "                self.totalReward += self.rewardPlace[place]\n",
    "\n",
    "    #     ...\n",
    "    def setForbidden(self,place):\n",
    "        self.forbiddenPlace.append(np.array(place))\n",
    "        self.blockedPlace.append(np.array(place))\n",
    "    def setIce(self,place):\n",
    "        self.icePlace.append(np.array(place))\n",
    "    def setWind(self,place):\n",
    "        self.windPlace.append(np.array(place))\n",
    "    def setTeleportation(self,origin ,destination ,reward = 0):\n",
    "        origin = tuple(origin)\n",
    "        destination = np.array(destination)\n",
    "        self.teleportation[origin]=destination\n",
    "        self.rewardPlace[origin] = reward\n",
    "\n",
    "    # A method to reset the gridworld:\n",
    "    def reset(self):\n",
    "        self.pos = np.array([0,0])\n",
    "    \n",
    "    \n",
    "    # A method to output the world:\n",
    "    def drawWorld(self):\n",
    "        print(self)\n",
    "    \n",
    "    def giveIndex(self,array):\n",
    "        return [int(self.height-list(array)[1]-1),int(list(array)[0])]\n",
    "    #string implementation\n",
    "    def __str__(self) -> str:\n",
    "        worldRepresentation = [[\"X\" if np.array_equal(([x,y]), self.pos) else \"_\" for x in range(self.width)] for y in reversed(range(self.height))]\n",
    "\n",
    "        #show special place\n",
    "        for teleportStart, teleportFinish in self.teleportation.items():\n",
    "            worldRepresentation[self.giveIndex(teleportStart)[0]][self.giveIndex(teleportStart)[1]] = \"S\"\n",
    "            worldRepresentation[self.giveIndex(teleportFinish)[0]][self.giveIndex(teleportFinish)[1]] = \"F\"\n",
    "\n",
    "        for blockedPosition in self.blockedPlace:\n",
    "            worldRepresentation[self.giveIndex(blockedPosition)[0]][self.giveIndex(blockedPosition)[1]] = \"B\"\n",
    "\n",
    "        for icePosition in self.icePlace:\n",
    "            worldRepresentation[self.giveIndex(icePosition)[0]][self.giveIndex(icePosition)[1]] = \"I\"\n",
    "        for windPosition in self.windPlace:\n",
    "            worldRepresentation[self.giveIndex(windPosition)[0]][self.giveIndex(windPosition)[1]] = \"W\"\n",
    "\n",
    "        #redraw X, in case it was erased\n",
    "        worldRepresentation[self.giveIndex(self.pos)[0]][self.giveIndex(self.pos)[1]] = \"X\"\n",
    "\n",
    "        worldRepresentation = [\" \".join(line) for line in worldRepresentation]\n",
    "        return \"\\n\".join(worldRepresentation)\n",
    "    \n",
    "    # (!) More difficult:\n",
    "    # A method to interactively \"play\" in the gridworld:\n",
    "    # def play(??):\n",
    "    #     ...\n",
    "    \n",
    "\n",
    "    # Any other method that might be useful to the user\n",
    "    # ...\n",
    "\n",
    "    # Any \"helper\" methods you use internally\n",
    "    # ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have implemented the basic methods above, you should be able to walk around in an empty gridworld! 🎉\n",
    "\n",
    "To make things more interesting, implement for example:\n",
    "- Positive rewards for reaching certain squares\n",
    "- Negative rewards for \"illegal\" moves\n",
    "- Blocked squares that cannot be entered\n",
    "- Teleporting squares that move the player to another spot. This is useful to avoid optimal \"back-and-forth\" policies.\n",
    "- A `.previewMove()` method to simulate given actions from a given start square.\n",
    "- A random effect (ice, wind, ...) that changes the effect of some actions.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can test individual aspects of your gridworld class with short code cells.\n",
    "\n",
    "You can re-run cells or run them out of order, but it is recommended that the notebook still works if you `Run All` in a fresh jupyter session.\n",
    "\n",
    "If you implemented an interactive `.play()` method, you might not be able to test it from inside a jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new gridworld instance\n",
    "gw = GridWorld(5,6)\n",
    "gw.setWind([1,0])\n",
    "gw.setWind([0,1])\n",
    "gw.setIce([2,2])\n",
    "gw.setForbidden([1,2])\n",
    "gw.setTeleportation([1,1],[4,4],15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "windy\n",
      "[0 0]\n",
      "_ _ _ _ F _\n",
      "_ _ _ _ _ _\n",
      "_ B I _ _ _\n",
      "W S _ _ _ _\n",
      "X W _ _ _ _\n",
      "[ 0 -1]\n",
      "-1\n",
      "_ _ _ _ F _\n",
      "_ _ _ _ _ _\n",
      "_ B I _ _ _\n",
      "W S _ _ _ _\n",
      "X W _ _ _ _\n",
      "[ 0 -1]\n",
      "-2\n",
      "_ _ _ _ F _\n",
      "_ _ _ _ _ _\n",
      "_ B I _ _ _\n",
      "W S _ _ _ _\n",
      "X W _ _ _ _\n",
      "[-1  0]\n",
      "-3\n",
      "_ _ _ _ F _\n",
      "_ _ _ _ _ _\n",
      "_ B I _ _ _\n",
      "W S _ _ _ _\n",
      "X W _ _ _ _\n"
     ]
    }
   ],
   "source": [
    "# Take some arbitrary actions\n",
    "T=4\n",
    "for _ in range(T):\n",
    "    gw.step(random.choice(DIRECTION))\n",
    "    gw.drawWorld()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDict={\"w\":UP,\"a\":LEFT,\"s\":DOWN,\"d\":RIGHT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input handler\n",
    "path = input()\n",
    "for letter in path:\n",
    "    if letter in inputDict:\n",
    "        gw.step(inputDict[key])\n",
    "        gw.drawWorld()\n",
    "    else:\n",
    "        print( letter, \" is not a direction. use WASD instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy evaluation, policy improvement, and optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNICODE_DIRECTION=[\"\\u2192\",\"\\u2190\",\"\\u2191\",\"\\u2193\"]\n",
    "def showPolicy(policy,grid:GridWorld):\n",
    "    for j in reversed(range(grid.height)):\n",
    "            for i in range(grid.width):\n",
    "                for key,direction in enumerate(DIRECTION):\n",
    "                        if (policy[(i,j)]==direction).all():\n",
    "                              print(UNICODE_DIRECTION[key],end=\"\")\n",
    "                    \n",
    "                print(\" \",end=\"\")\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIRECTION : [1 0] →\n",
      "DIRECTION : [-1  0] ←\n",
      "DIRECTION : [0 1] ↑\n",
      "DIRECTION : [ 0 -1] ↓\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(\"DIRECTION :\", DIRECTION[i], UNICODE_DIRECTION[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written inside the Gridworld a function that evaluates an action given a state and a value function. We can use this function to evaluate a given policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policyEvaluation(policy,grid:GridWorld):\n",
    "    values=np.zeros((grid.width,grid.height))\n",
    "    newValues=np.zeros((grid.width,grid.height))\n",
    "    delta = float('inf')\n",
    "    while delta>THETA:\n",
    "        for j in range(grid.height):\n",
    "            for i in range(grid.width):\n",
    "                newValues[i,j]=grid.evalAction(policy[i,j],values,theoricalPos=np.array([i,j]))\n",
    "        delta=max([abs(values[i,j]-newValues[i,j]) for j in range(grid.height) for i in range(grid.width)])\n",
    "        values=newValues.copy()\n",
    "    return values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): array([ 0, -1]), (1, 0): array([0, 1]), (2, 0): array([0, 1]), (3, 0): array([0, 1]), (4, 0): array([0, 1]), (5, 0): array([ 0, -1]), (0, 1): array([1, 0]), (1, 1): array([ 0, -1]), (2, 1): array([ 0, -1]), (3, 1): array([-1,  0]), (4, 1): array([0, 1]), (5, 1): array([1, 0]), (0, 2): array([ 0, -1]), (1, 2): array([0, 1]), (2, 2): array([ 0, -1]), (3, 2): array([ 0, -1]), (4, 2): array([0, 1]), (5, 2): array([-1,  0]), (0, 3): array([0, 1]), (1, 3): array([ 0, -1]), (2, 3): array([0, 1]), (3, 3): array([-1,  0]), (4, 3): array([ 0, -1]), (5, 3): array([ 0, -1]), (0, 4): array([ 0, -1]), (1, 4): array([1, 0]), (2, 4): array([ 0, -1]), (3, 4): array([1, 0]), (4, 4): array([0, 1]), (5, 4): array([-1,  0])}\n",
      "↓ → ↓ → ↑ ← \n",
      "↑ ↓ ↑ ← ↓ ↓ \n",
      "↓ ↑ ↓ ↓ ↑ ← \n",
      "→ ↓ ↓ ← ↑ → \n",
      "↓ ↑ ↑ ↑ ↑ ↓ \n"
     ]
    }
   ],
   "source": [
    "policy = dict()\n",
    "for j in range(gw.height):\n",
    "    for i in range(gw.width):\n",
    "        policy[i,j] = random.choice(DIRECTION)\n",
    "print(policy)\n",
    "showPolicy(policy,gw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policyImprovement(values,grid:GridWorld):\n",
    "    newPolicy = dict()\n",
    "    for j in range(grid.height):\n",
    "            for i in range(grid.width):\n",
    "                valuesDirection = dict()\n",
    "                for key, action in enumerate(DIRECTION):\n",
    "                    if (any( (np.array([i,j]) + action == place ).all() for place in grid.forbiddenPlace)):\n",
    "                         continue\n",
    "                    else:\n",
    "                        valuesDirection[key] = gw.evalAction(action,values,theoricalPos=np.array([i,j]))\n",
    "                newPolicy[(i,j)] = DIRECTION[max(valuesDirection,key=valuesDirection.get)]\n",
    "    return newPolicy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to policy iteration algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57550/866829050.py:9: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  delta=max([abs(values[i,j]-newValues[i,j]) for j in range(grid.height) for i in range(grid.width)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ → ← ← ↓ ↓ \n",
      "↓ → → → → ← \n",
      "↓ → → → → ← \n",
      "→ ← ← → ← ← \n",
      "↑ ↑ ← → ← ← \n",
      "--------------------------------------------------------------------------------\n",
      "↓ → → → → ← \n",
      "↓ ← ↓ → → ← \n",
      "↓ → ↓ → → ← \n",
      "→ → ← ← → ← \n",
      "→ ↑ ↑ ← → ← \n",
      "--------------------------------------------------------------------------------\n",
      "↓ ← ↓ → → ← \n",
      "↓ → ↓ ← → ← \n",
      "↓ → ↓ ↓ → ← \n",
      "→ → ← ← ← ← \n",
      "→ ↑ ↑ ← ← ← \n",
      "--------------------------------------------------------------------------------\n",
      "↓ → ↓ ← → ← \n",
      "↓ → ↓ ← ← ← \n",
      "↓ → ↓ ↓ ← ↓ \n",
      "→ → ← ← ← ← \n",
      "→ ↑ ↑ ← ← ← \n",
      "--------------------------------------------------------------------------------\n",
      "↓ → ↓ ← ← ↓ \n",
      "↓ → ↓ ← ← ← \n",
      "↓ → ↓ ↓ ← ← \n",
      "→ → ← ← ← ← \n",
      "→ ↑ ↑ ← ← ← \n",
      "--------------------------------------------------------------------------------\n",
      "↓ → ↓ ← ← ← \n",
      "↓ → ↓ ← ← ← \n",
      "↓ → ↓ ↓ ← ← \n",
      "→ → ← ← ← ← \n",
      "→ ↑ ↑ ← ← ← \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "value=[]\n",
    "while True:\n",
    "    newValue=policyEvaluation(policy,gw)\n",
    "    newPolicy=policyImprovement(newValue,gw)\n",
    "    if np.all([np.all(x==y) for x,y in zip(list(newPolicy.values()),list(policy.values()))]):\n",
    "        break\n",
    "    policy=newPolicy.copy()\n",
    "    value=newValue.copy()\n",
    "    showPolicy(policy,gw)\n",
    "    print(\"--------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↓ → ↓ ← ← ← \n",
      "↓ → ↓ ← ← ← \n",
      "↓ → ↓ ↓ ← ← \n",
      "→ → ← ← ← ← \n",
      "→ ↑ ↑ ← ← ← \n"
     ]
    }
   ],
   "source": [
    "showPolicy(policy,gw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57550/4183456282.py:9: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  delta=max([abs(values[j,i]-newValues[j,i]) for j in range(gw.width) for i in range(gw.height)])\n"
     ]
    }
   ],
   "source": [
    "values=np.zeros((gw.width,gw.height))\n",
    "newValues=np.zeros((gw.width,gw.height))\n",
    "delta = float('inf')\n",
    "while delta>THETA:\n",
    "    for j in range(gw.height):\n",
    "        for i in range(gw.width):\n",
    "            actionValuesFromState=[gw.evalAction(action,values,theoricalPos=np.array([i,j])) for action in DIRECTION]\n",
    "            newValues[i,j]=np.max(actionValuesFromState)\n",
    "    delta=max([abs(values[j,i]-newValues[j,i]) for j in range(gw.width) for i in range(gw.height)])\n",
    "    values=newValues.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((gw.width,gw.height))[gw.width-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31.69685048 36.62749449 31.3287054  28.19569021 25.37580397]\n",
      " [36.62749449 35.62749449        -inf 29.66827054 26.70061049]\n",
      " [32.96474505 36.62749449 32.96474505 32.96474505 29.66827054]\n",
      " [29.66827054 32.96474505 29.66827054 29.66827054 26.70061049]\n",
      " [26.70061049 29.66827054 26.70061049 26.70061049 24.03054944]\n",
      " [24.03054944 26.70061049 24.03054944 24.03054944 21.62749449]]\n"
     ]
    }
   ],
   "source": [
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↓ → ↓ ← ← ← \n",
      "↓ → ↓ ← ← ← \n",
      "↓ → ↓ ↓ ← ← \n",
      "→ → ← ← ← ← \n",
      "→ ↑ ↑ ← ← ← \n"
     ]
    }
   ],
   "source": [
    "optimalPolicy=policyImprovement(values,gw)\n",
    "showPolicy(optimalPolicy,gw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ F _\n",
      "_ _ _ _ _ _\n",
      "_ B I _ _ _\n",
      "W S _ _ _ _\n",
      "X W _ _ _ _\n"
     ]
    }
   ],
   "source": [
    "gw.drawWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at  (1, 2)  action  [1 0]  is impossible\n",
      "at  (1, 2)  action  [-1  0]  is impossible\n",
      "at  (1, 2)  action  [0 1]  is impossible\n",
      "at  (1, 2)  action  [ 0 -1]  is impossible\n"
     ]
    }
   ],
   "source": [
    "for j in range(gw.height):\n",
    "    for i in range(gw.width):\n",
    "        for action in DIRECTION:\n",
    "            if gw.evalAction(action,values,theoricalPos=np.array([i,j]))==-float(\"inf\"):\n",
    "                print(\"at \", (i,j), \" action \", action, \" is impossible\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "57c3bdca5a68245cc50b723d4c81bd24b2e1aa8df4f8df0134d90b967dbed3e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
